/*

BUFFER C: Raytracing

Original code provided by Dan Buckstien
Modified by Steven Annunziato
Modifications are adapted from Peter Shirley's Ray Tracing in One Weekend
https://raytracing.github.io/books/RayTracingInOneWeekend.html#rays,asimplecamera,andbackground

*/

// get point on ray
vec3 at(Ray ray, float t)
{
	return ray.origin.xyz + ray.direction.xyz * t;
}    
 
// determine the correct way to set the face normal
void setFaceNormal(Ray ray, in vec3 outwardNormal, out HitRecord record) {
    if (dot(ray.direction.xyz, outwardNormal) > 0.0) {
        // ray is inside the sphere
        record.normal = -outwardNormal;
        record.frontFace = false;
    }
    else {
        // ray is outside the sphere
        record.normal = outwardNormal;
        record.frontFace = true;
    }
}

// -----------------------------------------------------------
// INTERSECTION

// detect if a ray has intersected a sphere with clamped t value
bool hitSphere(in vec3 center, in float radius, in Ray ray, in float tMin, in float tMax, out HitRecord record)
{
	// calculate if the ray hits a sphere
    vec3 oc = ray.origin.xyz - center;
    float a = dot(ray.direction, ray.direction);
    float half_b = dot(oc, ray.direction.xyz);
    float c = dot(oc, oc) - radius * radius;
    float discriminant = half_b * half_b - a * c;
    
    if (discriminant > 0.0) {
        float root = sqrt(discriminant);
        
        float temp = (-half_b - root) / a;
        if (temp > tMin && temp < tMax) {
            // calculate hit record information
            record.t = temp;
            record.point = at(ray, temp);
            vec3 outwardNormal = (record.point - center) / radius;
            setFaceNormal(ray, outwardNormal, record);
            return true;
        }
        
        temp = (-half_b + root) / a;
        if (temp > tMin && temp < tMax) {
            // calculate hit record information
            record.t = temp;
            record.point = at(ray, temp);
            vec3 outwardNormal = (record.point - center) / radius;
            setFaceNormal(ray, outwardNormal, record);
            return true;
        }
    }
    
    return false;
    
}

// consumes an array of spheres and a ray, and determines if any of the spheres have been hit
bool hitSphereArray(in Sphere spheres[10], in Ray ray, in float tMin, in float tMax, out HitRecord record)
{
    HitRecord tempRecord;
    bool hitAnything = false;
    float closestSoFar = tMax;
    
    // loop through each sphere to determine if there is a hit
    for (int i = spheres.length() - 1; i >= 0; --i)
    {
        if (hitSphere(spheres[i].center, spheres[i].radius, ray, tMin, closestSoFar, tempRecord))
        {
            hitAnything = true;
            closestSoFar = tempRecord.t;
            record = tempRecord;
        }
    }
    
    // nothing is hit
    return hitAnything;
}

// ---------------------------------------------------------------------
// LIGHTING

// calculations for diffuse light scattering
float calcDiffuse(in sPointLight light, in vec3 position, in vec3 normal, out vec3 lightVector)
{
    // lambertian reflectance
    //lightVector = light.center.xyz - position;
    float lightDist = sqrt(dot(lightVector, lightVector));
    float invDist = 1.0 / lightDist;
    lightVector *= invDist; // light vector is now normalized
    float diffuseCoefficient = max(0.0, dot(normal, lightVector));
    // attenuation (light falloff)
    float invIntensity = 1.0 / light.intensity;
    float attenuatedIntensity = 1.0 / (1.0 + (lightDist * invIntensity) + square(lightDist * invIntensity));
    return diffuseCoefficient * attenuatedIntensity;
}

// calculations for specular highlights
float phongSpecular(in vec3 lightVector, in vec3 viewVector, in vec3 normal)
{
    // phong reflectance
    vec3 reflectedLight = reflect(-lightVector, normal);
    float specularCoefficient = max(0.0, dot(viewVector, reflectedLight));
    return pow64(specularCoefficient);
}

float blinnPhongSpecular(in vec3 lightVector, in vec3 viewVector, in vec3 normal)
{
    // blinn-phong reflectance
    vec3 temp = lightVector + viewVector;
    float invLength = 1.0 / sqrt(dot(temp, temp));
    vec3 halfwayVector = temp * invLength;
    float specularCoefficient = max(0.0, dot(normal, halfwayVector));
    return pow256(specularCoefficient);   
}

vec4 calcLighting(Ray ray, HitRecord record, vec3 eyePos)
{
    
    // lighting properties
    float intensity = 20.0;
    
    // light definitions
    sPointLight light1;
    initPointLight(light1, vec3(sin(iTime) * 5.0, 1.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0), intensity);
    sPointLight light2;
    initPointLight(light2, vec3(-1.0, 1.0, 0.0), vec4(0.0, 1.0, 0.0, 1.0), intensity * 1.75);
    sPointLight light3;
    initPointLight(light3, vec3(1.0, 1.0, 0.0), vec4(0.0, 0.0, 1.0, 1.0), intensity * 0.8);
    sPointLight light4;
    initPointLight(light4, vec3(2.0, 1.0, 0.0), vec4(1.0, 0.0, 1.0, 1.0), intensity * 0.5);
    // array of lights
    sPointLight lights[4];
    lights[0] = light1;
    //lights[1] = light2;
    //lights[2] = light3;
    //lights[3] = light4;
    
    
    // SHADING
    // light and color properties
    vec4 diffuseColor = vec4(1.0, 1.0, 1.0, 1.0);
    float ambientIntensity = 0.1;
    vec4 ambientColor = vec4(1.0, 1.0, 1.0, 1.0);
    vec4 specularHighlightColor = vec4(1.0, 1.0, 1.0, 1.0);

    // final calculation
    vec4 finalAmbient = ambientIntensity * ambientColor;
    vec4 summedColor = vec4(0.0);
    // loop through each light
    for (int i = lights.length() - 1; i >= 0; --i) {

        vec3 lightVector = lights[i].center.xyz - record.point;
        vec3 viewVector = normalize(eyePos - record.point); // OPTIMIZE

        // first calculate diffuse intensity
        float diffuseIntensity = calcDiffuse(lights[i], record.point, record.normal, lightVector);

        // next calculate specular intensity
        float specularIntensity = blinnPhongSpecular(lightVector, viewVector, record.normal);
        //specularIntensity = 0.0;

        // final calculation
        summedColor += (diffuseIntensity * diffuseColor + specularIntensity * specularHighlightColor) * lights[i].color;
    }
    return finalAmbient + summedColor;   
}

// ---------------------------------------------------------------------
// RENDERING

// calcViewport: calculate the viewing plane (viewport) coordinate
//    viewport:       output viewing plane coordinate
//    ndc:            output normalized device coordinate
//    uv:             output screen-space coordinate
//    aspect:         output aspect ratio of screen
//    resolutionInv:  output reciprocal of resolution
//    viewportHeight: input height of viewing plane
//    fragCoord:      input coordinate of current fragment (in pixels)
//    resolution:     input resolution of screen (in pixels)
void calcViewport(out vec2 viewport, out vec2 ndc, out vec2 uv,
                  out float aspect, out vec2 resolutionInv,
                  in float viewportHeight, in vec2 fragCoord, in vec2 resolution)
{
    // inverse (reciprocal) resolution = 1 / resolution
    resolutionInv = 1.0 / resolution;
    
    // aspect ratio = screen width / screen height
    aspect = resolution.x * resolutionInv.y;

    // uv = screen-space coordinate = [0, 1) = coord / resolution
    uv = fragCoord * resolutionInv;
    //uv = (fragCoord + vec2(randomFloat(fragCoord))) * resolutionInv;

    // ndc = normalized device coordinate = [-1, +1) = uv*2 - 1
    ndc = uv * 2.0 - 1.0;

    // viewport: x = [-aspect*h/2, +aspect*h/2), y = [-h/2, +h/2)
    viewport = ndc * (vec2(aspect, 1.0) * (viewportHeight * 0.5));
}

// calcRay: calculate the ray direction and origin for the current pixel
//    ray:			output direction and origin of ray
//	  eyePos:		position of camera or eye
//    viewport:     input viewing plane coordinate (use above function to calculate)
//    focalLength:  input distance to viewing plane
void calcRay(out Ray ray, in vec3 eyePos,
             in vec2 viewport, in float focalLength)
{
    // ray origin relative to viewer is the origin
    // w = 1 because it represents a point; can ignore when using
    ray.origin = vec4(eyePos.xyz, 1.0);

    // ray direction relative to origin is based on viewing plane coordinate
    // w = 0 because it represents a direction; can ignore when using
    ray.direction = vec4(viewport.x, viewport.y, -focalLength, 0.0);
}

// calcColor: calculate the color of a pixel given a ray
//    rayDirection: input ray direction
//    rayOrigin:    input ray origin
vec4 calcColor(in Ray ray, in Sphere spheres[10], in vec3 eyePos)
{

    // create hit records for all objects in the world (aka the array of spheres)
    HitRecord record;
    if (hitSphereArray(spheres, ray, 0.0, 10000.0, record))
    {
        //return vec4(0.5 * (record.normal + vec3(1.0)), 1.0); // shade based on surface normals
        return calcLighting(ray, record, eyePos);
    }
    
    // calculate unit vector for the current ray direction
    float invLength = 1.0 / length(ray.direction.xyz); // inefficient square root necessary here
    vec4 unitDirection = vec4(ray.direction.xyz * invLength, ray.direction.w);
    
    // output a gradient in the background
    float t = 0.5 * (unitDirection.y + 1.0);
    return (1.0 - t) * vec4(1.0, 1.0, 1.0, 1.0) + t * vec4(0.5, 0.7, 1.0, 1.0);
}

// mainImage: process the current pixel (exactly one call per pixel)
//    fragColor: output final color for current pixel
//    fragCoord: input location of current pixel in image (in pixels)
void mainImage(out vec4 fragColor, in vec2 fragCoord)
{
    // viewing plane (viewport) info
    vec2 viewport, ndc, uv, resolutionInv;
    float aspect;
    const float viewportHeight = 2.0, focalLength = 1.0;
    vec3 eyePos = vec3(0.0, 0.5, 0.0);

    // ray
    Ray ray;

    // setup
    calcViewport(viewport, ndc, uv, aspect, resolutionInv,
                 viewportHeight, fragCoord, iResolution.xy);
    calcRay(ray, eyePos,
            viewport, focalLength);

    // create world
    float yVal1 = texture(iChannel0, vec2(0.0, 0.0)).x;//abs(sin(iTime * 2.75 + 20.0));
    float yVal2 = texture(iChannel0, vec2(0.33, 0.0)).x;//abs(sin(iTime * 2.75 + 40.0));
    float yVal3 = texture(iChannel0, vec2(0.66, 0.0)).x;//abs(sin(iTime * 2.75));
    Sphere sphere1 = Sphere(vec3(0.0, yVal1, -2.25), 0.5);
    Sphere sphere2 = Sphere(vec3(1.0, yVal2, -1.5), 0.5);
    Sphere sphere3 = Sphere(vec3(-1.0, yVal3, -1.5), 0.5);
    Sphere ground = Sphere(vec3(0.0, -100.5, -1.0), 100.0);
    Sphere world[10];
    world[0] = sphere1;
    world[1] = ground;
    world[2] = sphere2;
    world[3] = sphere3;
    
    // calculate ray traced color (with antialiasing)
    /*int numberOfSamples = 20;
    float invSamples = 1.0 / float(numberOfSamples);
    vec4 finalColor = vec4(0.0);
    for (int i = numberOfSamples - 1; i > 0; --i) {
        ray.origin += vec4(vec3(randomFloat(fragCoord) * 0.0002), 0.0);
        finalColor += calcColor(ray, world);
    }
    fragColor = finalColor * invSamples;*/
    
    // final color
    fragColor = calcColor(ray, world, eyePos);
    
}

/*

#version 300 es

// inputs (later)
// uniforms (see shader inputs above)

// output
layout (location = 0) out vec4 rtFragColor;

// specific to shadertoy
void mainImage(out vec4 fragColor, in vec2 fragCoord);

void main()
{
	// shadertoy specific
	mainImage(rtFragColor, gl_FragCoord.xy); // gl_FragCoord.xy is from the hardware
}

*/