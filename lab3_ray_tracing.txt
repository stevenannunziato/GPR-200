/*

Original code provided by Dan Buckstien
Modified by Steven Annunziato
All modifications are adapted from Peter Shirley's Ray Tracing in One Weekend
https://raytracing.github.io/books/RayTracingInOneWeekend.html#rays,asimplecamera,andbackground

*/

struct Sphere {
    vec3 origin;
    float radius;
};
struct HitRecord {
	vec3 point;
    float t;
    vec3 normal;
    bool frontFace;
};

// get point on ray
vec3 at(vec4 rayDirection, vec4 rayOrigin, float t)
{
	return rayOrigin.xyz + rayDirection.xyz * t;
}    
 
// determine the correct way to set the face normal
void setFaceNormal(vec4 rayDirection, vec4 rayOrigin, in vec3 outwardNormal, out HitRecord record) {
    if (dot(rayDirection.xyz, outwardNormal) > 0.0) {
        // ray is inside the sphere
        record.normal = -outwardNormal;
        record.frontFace = false;
    }
    else {
        // ray is outside the sphere
        record.normal = outwardNormal;
        record.frontFace = true;
    }
}

// detect if a ray has hit a sphere with clamped t value
bool hitSphere(vec3 center, float radius, vec4 rayDirection, vec4 rayOrigin, float tMin, float tMax, out HitRecord record)
{
	// calculate if the ray hits a sphere
    vec3 oc = rayOrigin.xyz - center;
    float a = dot(rayDirection, rayDirection);
    float half_b = dot(oc, rayDirection.xyz);
    float c = dot(oc, oc) - radius * radius;
    float discriminant = half_b * half_b - a * c;
    
    if (discriminant > 0.0) {
        float root = sqrt(discriminant);
        
        float temp = (-half_b - root) / a;
        if (temp > tMin && temp < tMax) {
            record.t = temp;
            record.point = at(rayDirection, rayOrigin, temp);
            vec3 outwardNormal = (record.point - center) / radius;
            setFaceNormal(rayDirection, rayOrigin, outwardNormal, record);
            return true;
        }
        
        temp = (-half_b + root) / a;
        if (temp > tMin && temp < tMax) {
            record.t = temp;
            record.point = at(rayDirection, rayOrigin, temp);
            vec3 outwardNormal = (record.point - center) / radius;
            setFaceNormal(rayDirection, rayOrigin, outwardNormal, record);
            return true;
        }
    }
    
    return false;
    
    /*// determine value for hit
    if (discriminant < 0.0) {
        return -1.0;
    }
    else {
        return (-half_b - sqrt(discriminant)) / a;
    }*/
}
    
// detect if a ray has hit a sphere (legacy version - to be deleted)
float hitSphere(vec3 center, float radius, vec4 rayDirection, vec4 rayOrigin)
{
	// calculate if the ray hits a sphere
    vec3 oc = rayOrigin.xyz - center;
    float a = dot(rayDirection, rayDirection);
    float half_b = dot(oc, rayDirection.xyz);
    float c = dot(oc, oc) - radius * radius;
    float discriminant = half_b * half_b - a * c;
    
    // determine value for hit
    if (discriminant < 0.0) {
        return -1.0;
    }
    else {
        return (-half_b - sqrt(discriminant)) / a;
    }
}

// calcViewport: calculate the viewing plane (viewport) coordinate
//    viewport:       output viewing plane coordinate
//    ndc:            output normalized device coordinate
//    uv:             output screen-space coordinate
//    aspect:         output aspect ratio of screen
//    resolutionInv:  output reciprocal of resolution
//    viewportHeight: input height of viewing plane
//    fragCoord:      input coordinate of current fragment (in pixels)
//    resolution:     input resolution of screen (in pixels)
void calcViewport(out vec2 viewport, out vec2 ndc, out vec2 uv,
                  out float aspect, out vec2 resolutionInv,
                  in float viewportHeight, in vec2 fragCoord, in vec2 resolution)
{
    // inverse (reciprocal) resolution = 1 / resolution
    resolutionInv = 1.0 / resolution;
    
    // aspect ratio = screen width / screen height
    aspect = resolution.x * resolutionInv.y;

    // uv = screen-space coordinate = [0, 1) = coord / resolution
    uv = fragCoord * resolutionInv;

    // ndc = normalized device coordinate = [-1, +1) = uv*2 - 1
    ndc = uv * 2.0 - 1.0;

    // viewport: x = [-aspect*h/2, +aspect*h/2), y = [-h/2, +h/2)
    viewport = ndc * (vec2(aspect, 1.0) * (viewportHeight * 0.5));
}

// calcRay: calculate the ray direction and origin for the current pixel
//    rayDirection: output direction of ray from origin
//    rayOrigin:    output origin point of ray
//    viewport:     input viewing plane coordinate (use above function to calculate)
//    focalLength:  input distance to viewing plane
void calcRay(out vec4 rayDirection, out vec4 rayOrigin,
             in vec2 viewport, in float focalLength)
{
    // ray origin relative to viewer is the origin
    // w = 1 because it represents a point; can ignore when using
    rayOrigin = vec4(0.0, 0.0, 0.0, 1.0);

    // ray direction relative to origin is based on viewing plane coordinate
    // w = 0 because it represents a direction; can ignore when using
    rayDirection = vec4(viewport.x, viewport.y, -focalLength, 0.0);
}

// calcColor: calculate the color of a pixel given a ray
//    rayDirection: input ray direction
//    rayOrigin:    input ray origin
vec4 calcColor(in vec4 rayDirection, in vec4 rayOrigin)
{
    // DUMMY RESULT: OUTPUT RAY DIRECTION AS-IS
    // -> what does the ray look like as color?
    //return rayDirection;
    
    // calculate unit vector for the current ray direction
    float invLength = 1.0 / length(rayDirection.xyz); // inefficient square root necessary here
    vec4 unitDirection = vec4(rayDirection.xyz * invLength, rayDirection.w);
    
    // determine if the ray hits a sphere and shade based on surface normals
    vec3 center = vec3(0.0, 0.0, -1.0);
    float radius = 0.5;
    float t = hitSphere(center, radius, rayDirection, rayOrigin);
    if (t > 0.0) {
        vec3 normal = at(rayDirection, rayOrigin, t) - center;
        normal /= length(normal); // this line can be heavily optimized
        return 0.5 * vec4(normal.x + 1.0, normal.y + 1.0, normal.z + 1.0, 1.0);
    }
    
    // output a gradient in the background
    t = 0.5 * (unitDirection.y + 1.0);
    return (1.0 - t) * vec4(1.0, 1.0, 1.0, 1.0) + t * vec4(0.5, 0.7, 1.0, 1.0);
}

// mainImage: process the current pixel (exactly one call per pixel)
//    fragColor: output final color for current pixel
//    fragCoord: input location of current pixel in image (in pixels)
void mainImage(out vec4 fragColor, in vec2 fragCoord)
{
    // viewing plane (viewport) info
    vec2 viewport, ndc, uv, resolutionInv;
    float aspect;
    const float viewportHeight = 2.0, focalLength = 1.0;

    // ray
    vec4 rayDirection, rayOrigin;

    // setup
    calcViewport(viewport, ndc, uv, aspect, resolutionInv,
                 viewportHeight, fragCoord, iResolution.xy);
    calcRay(rayDirection, rayOrigin,
            viewport, focalLength);

    // calculate ray traced color per pixel
    fragColor = calcColor(rayDirection, rayOrigin);
    
    // color
    //fragColor = calcColor(rayDirection, rayOrigin);

    // TEST COLOR:
    //  -> what do the other things calculated above look like?
    //fragColor = vec4(viewport, 0.0, 0.0);
    //fragColor = vec4(ndc, 0.0, 0.0); // origin is in the middle of the screen
    //fragColor = vec4(uv, 0.0, 0.0);
    
    
}

/*

#version 300 es

// inputs (later)
// uniforms (see shader inputs above)

// output
layout (location = 0) out vec4 rtFragColor;

// specific to shadertoy
void mainImage(out vec4 fragColor, in vec2 fragCoord);

void main()
{
	// shadertoy specific
	mainImage(rtFragColor, gl_FragCoord.xy); // gl_FragCoord.xy is from the hardware
}

*/